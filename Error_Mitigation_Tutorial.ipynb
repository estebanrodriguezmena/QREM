{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Mitigation\n",
    "\n",
    "This notebook contains theoretical background and examples for using our Error Mitigation module with Qiskit. \n",
    "We recommend to first read our [Quantum Detector Tomography Tutorial](QDT_Tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical background\n",
    "Here we describe main theoretical concepts related to mitigation procedure. For more detailed description, see Ref. [0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical noise model\n",
    "\n",
    "Let us denote by $\\mathbf{M}$ a POVM describing noisy detector and $\\mathbf{P}$ denote ideal measurement. In classical noise model, we assume that the relation between the two is given by stochastic, invertible map $\\Lambda$:\n",
    "\n",
    "$$ \\mathbf{M} = \\Lambda \\mathbf{P}.$$\n",
    "\n",
    "Let us denote by $\\mathbf{p}_{exp}$ vector of probabilities obtained on a noisy detector $\\mathbf{M}$ measuring any quantum state, and by $\\mathbf{p_{ideal}}$ the analogous vector for ideal detector (for the same quantum state). From linearity of the Born's rule, it follows that two vectors are related by the same stochastic map as POVMs:\n",
    "\n",
    "$$ \\mathbf{p_{exp}} = \\Lambda \\mathbf{p_{ideal}}. $$\n",
    "\n",
    "Recall that we assumed that $\\Lambda$ is invertible. Hence by multiplying last equation by $\\Lambda^{-1}$ from both sides, we obtain\n",
    "\n",
    "$$ \\Lambda^{-1} \\mathbf{p_{exp}} = \\mathbf{p_{ideal}}. $$\n",
    "\n",
    "Effectively, by this kind of postprocessing, we obtain statistics which we would have obtained on the perfect detector devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deviations from noise model\n",
    "\n",
    "There are several ways in which real noise can deviate from our model. Here we will show the way how to hanlde them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effects  on mitigation\n",
    "Above we assumed a very specific noise model. In practice it is likely that it will not be fulfilled exactly. In such a scenario, we may perform the following decomposition of POVM $M$ describing our device:\n",
    "$$ \\mathbf{M} = \\Lambda \\mathbf{P} + \\mathbf{\\Delta}\\ ,$$\n",
    "where $\\Delta$ denotes a \"coherent\" part of the noise and $\\Lambda$, as previously, is some stochastic, invertible map. \n",
    "\n",
    "In such a case, we can relate probability vector obtained on the noisy detector to ideal one in manner similar as before\n",
    "\n",
    "$$ \\mathbf{p_{exp}} = \\Lambda \\mathbf{p_{ideal}} + \\mathbf{d}\\ , $$\n",
    "where $\\mathbf{d}$ denotes a disturbance of probability vector due to existence of coherent part of the noise.\n",
    "If we now multiply the above expression by inverse of the noise matrix, we obtain\n",
    "\n",
    "$$ \\Lambda^{-1} \\mathbf{p_{exp}} = \\mathbf{p_{ideal}} + \\Lambda^{-1} \\mathbf{d}, \\  $$\n",
    "\n",
    "\n",
    "This clearly does not leave us with ideal statistics $\\mathbf{p_{ideal}}$, but consists of additional deviation term $\\Lambda^{-1} \\mathbf{d}$ which appears due to non-classicity of noise. Fortunately, this does not preclude our mitigation from working! The correction clearly will not be perfect in this case, however if deviation is sufficiently small, it still might be better then performing no correction at all.\n",
    "\n",
    "We can upper-bound the TV distance of corrected probability distribution from the ideal one by expression\n",
    "$$\n",
    "D_{TV}\\left( \\Lambda^{-1} \\mathbf{p_{exp}},\\mathbf{p_{ideal}} \\right) \\leq ||\\Lambda^{-1}||_{1 \\to 1} D_{op}(\\mathbf{M}, \\Lambda \\mathbf{P}) \\,\n",
    "$$\n",
    "where the $1\\rightarrow 1$ norm is defined as\n",
    "$$\n",
    "||A||_{1\\rightarrow1} = \\sup_{||v||_1} ||Av||_1 \\ .\n",
    "$$\n",
    "\n",
    "It is easy to see that if the detector $\\mathbf{M}$ is related to $\\mathbf{P}$ via only classical noise $\\Lambda$, then the above expression yields $0$, hence the mitigation works perfectly.\n",
    "In the presence of coherent measurement noise, term $D_{op}(\\mathbf{M}, \\Lambda \\mathbf{P})$ may be regarded as a measure of non-classicity of the noise.\n",
    "\n",
    "#### How to choose decomposition?\n",
    "\n",
    "In general, we can always perform decomposition into \"classical\" and \"coherent\" part in infinitely many ways. However, for the ideal detector $P$ modeled as projective measurement in computational basis, there exists a perfectly natural ansatz. Namely, we propose to consider diagonal parts of POVM's $\\mathbf{M}$ elements to describe classical part of the noise. \n",
    "As a justification for such choice, note that elements of $\\mathbf{P}$ for such ideal detector model are diagonal, and the stochastic map would preserve the diagonality. \n",
    "\n",
    "Hence, after obtaining description of POVM $\\mathbf{M}$ from detector tomography, reconstruction of $\\Lambda$ can be achieved by taking only diagonal parts of POVM's elements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finite-size statistics\n",
    "#### Statistical noise\n",
    "So far we have assumed that we have access to actual (noisy) probability distribution $\\mathbf{p_{exp}}$. However, in real life what we can get is only an estimator of this distribution \n",
    "\n",
    "$$ \\mathbf{p_{exp}} \\xrightarrow[\\text{}]{\\text{finite-size sampling}} \\mathbf{p}_{\\mathbf{exp}}^{\\text{est}}\\ ,$$ \n",
    "which simply consists of experimental frequencies of occurances of particular outcomes. \n",
    "\n",
    "As a result, we will have some statistical noise in our estimator, which we can write as\n",
    "$$\n",
    "\\mathbf{p}_{\\mathbf{exp}}^{\\text{est}}  = \\mathbf{p}_{\\mathbf{exp}} + \\mathbf{s} \\ ,\n",
    "$$\n",
    "where $\\mathbf{s}$ is some vector of statistical deviations. \n",
    "\n",
    "Let us assume that we perform $n$-outcome measurement and gather $k$ samples (shots). Then the magnitude of those statistical deviations can be upper bound by\n",
    "$$\n",
    "D_{TV}\\left(\\mathbf{p}_{\\mathbf{exp}}^{\\text{est}} , \\mathbf{p}_{\\mathbf{exp}} \\right) \\leq \\sqrt{\\frac{\\log{\\left(2^n-2\\right)}-\\log{\\text{Pr}_{wrong}}}{2k}} \\equiv \\epsilon \\ .\n",
    "$$\n",
    "Bounds on statistical deviations are usually probabilitic, and in the above equation we choose parameter $\\text{Pr}_{wrong}$ such that\n",
    "$$\n",
    "1-\\text{Pr}_{wrong} = \\text{Pr}\\left(D_{TV}\\left(\\mathbf{p}_{\\mathbf{exp}}^{\\text{est}} , \\mathbf{p}_{\\mathbf{exp}} \\right) \\leq \\epsilon\\right) \\ .\n",
    "$$\n",
    "\n",
    "#### Effects on mitigation\n",
    "Now we want to determine how far (in TV distance) is our corrected estimated statistics vector $\\Lambda^{-1}\\mathbf{p}_{\\mathbf{exp}}^{\\text{est}}$ from ideal statistics $\\mathbf{p_{ideal}}$. \n",
    "This distance can be upper bounded by\n",
    "\n",
    "$$ D_{TV}\\left(\\Lambda^{-1} \\mathbf{p}_{\\mathbf{exp}}^{\\text{est}}, \\mathbf{p_{ideal}}\\right) \\leq \\underbrace{||\\Lambda^{-1}||_{1 \\to 1} D_{op}(\\mathbf{M}, \\Lambda \\mathbf{P})}_{\\text{coherent noise}} + \\underbrace{||\\Lambda^{-1}||_{1 \\to 1} \\epsilon}_{\\text{statistical noise}} =: \\delta. $$\n",
    "\n",
    "This sum consists of two parts. \n",
    "First qunatifies propagation of coherent errors under our correction and is the same as in previous subsection. \n",
    "The second term quantifies propagation of statistical noise. For more details see Ref. [0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quasiprobability vectors\n",
    "TODO: finish\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When is mitigation succesful?\n",
    "TODO: finish\n",
    "We propose a simple test to decide it. We say, that mitigation was as success if\n",
    "\n",
    "$$ \\delta + \\alpha < D_{op}(M^{exp}, M^{ideal}) + \\epsilon,$$\n",
    "\n",
    "where $\\delta$ was introduced in previous section, $\\alpha$ describes the distance between raw quasiprobability vector obtained during mitigation scheme and its closest probability vector (note, that it can be 0, if mitigation returned probability vector), and $\\epsilon$ is statistical error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigating the errors using our module\n",
    "\n",
    "In this section we will describe how to use our mitigation module. We will begin with showing general approach as to how to prepare the mitigator object and then, on several examples, we will show how to use it (on single and multi-qubit circuit results). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Quantum Detector Tomography\n",
    "Our error mitigation approach is based on the knowledge about the noise in the device's detector. Such knowledge can be obtained in procedure known as Quantum Detector Tomography (QDT). To perform QDT, one can follow the steps from our [QDT tutorial](https://github.com/fbm2718/QREM/blob/master/QDT_Tutorial.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import povmtools\n",
    "import ancillary_functions as anf\n",
    "import numpy as np\n",
    "\n",
    "from qiskit import IBMQ, Aer, execute\n",
    "from qiskit.providers.aer import noise\n",
    "\n",
    "from quantum_tomography_qiskit import detector_tomography_circuits\n",
    "from DetectorTomographyFitter import DetectorTomographyFitter\n",
    "from QDTErrorMitigator import QDTErrorMitigator\n",
    "\n",
    "# Choose qubit indices\n",
    "QDT_qubit_index = [3]\n",
    "\n",
    "# Select probe kets\n",
    "QDT_probe_kets = povmtools.pauli_probe_eigenkets\n",
    "\n",
    "# Generate circuits\n",
    "QDT_circuits = detector_tomography_circuits(QDT_qubit_index, QDT_probe_kets)\n",
    "\n",
    "# Get QDT circuits results\n",
    "backend = Aer.get_backend('qasm_simulator')  #  Get backed\n",
    "shots_number = 2000  # Define number of measurement repetitions\n",
    "QDT_job = execute(QDT_circuits, backend=backend, shots=shots_number)\n",
    "results = QDT_job.result()\n",
    "\n",
    "# Get ml_povm_estimator using DTF and results\n",
    "DTF = DetectorTomographyFitter()\n",
    "ml_povm_estimator = DTF.get_maximum_likelihood_povm_estimator([results], QDT_probe_kets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing mitigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the estimator of POVM, we can create QDTErrorMitigator object and prepare it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation and preparation of QDTErrorMitigator\n",
    "mitigator = QDTErrorMitigator()\n",
    "mitigator.prepare_mitigator(ml_povm_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With prepared mitigator object we gain access to several useful functionalities. For example, we can:\n",
    "* Correct results of qiskit job by using apply_correction_to_qiskit_job(Results) method.\n",
    "* Access error and correction matrices obtained from POVM given during preparation.\n",
    "\n",
    "In order to properly analyse the results of correction procedure, one have to be aware that in some cases raw application of $\\Lambda^{-1}$ to the results may yield quasiprobability (instead of probability) vectors. In such scenario our code finds closest probability vectors and returns them instead. Distances from raw quasiprobabilities to returned probabilities, can be accessed via distances_from_closest_probability_vector member of mitigator object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error bounds calculation\n",
    "\n",
    "With access to POVM and the error and correction matrices, we are able to calculate bounds on several errors. In particular, using povmtools module, we can calculate:\n",
    "\n",
    "* statistical error bound (using get_statistical_error_bound method),\n",
    "* coherent error bound (using gt_coherent_error_bound method),\n",
    "* correction error bound (using get_correction_error_bound_from_data or get_correction_error_bound_from_parameters method).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single qubit error mitigation scenario\n",
    "\n",
    "In this section two examples of mitigation for single qubit will be shown. In order to show, that our mitigation scheme is efficient, we first need to create a noisy backend simulator. We start with required imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister\n",
    "from qiskit import execute\n",
    "from qiskit import IBMQ, Aer\n",
    "from qiskit.providers.aer.noise import NoiseModel\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import povmtools\n",
    "from DetectorTomographyFitter import DetectorTomographyFitter\n",
    "from quantum_tomography_qiskit import detector_tomography_circuits\n",
    "from QDTErrorMitigator import QDTErrorMitigator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use standard qiskit methods to create noisy backend simulator. For this tutorial we will create simulator of IBM's Burlington device which is usually quite noisy. Here the assumed model is classical, hece all errors in mitigation will be due to statistical noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  What I want to have first is working noisy backend simulation. In order to do that, I will use qiskit noise model\n",
    "# and download properties of selected backend.\n",
    "\n",
    "# Build noise model from backend properties.\n",
    "provider = IBMQ.load_account()\n",
    "backend = provider.get_backend('ibmq_burlington')\n",
    "noise_model = NoiseModel.from_backend(backend)\n",
    "\n",
    "# Get coupling map from backend, why not.\n",
    "coupling_map = backend.configuration().coupling_map\n",
    "\n",
    "# Get basis gates from noise model.\n",
    "basis_gates = noise_model.basis_gates\n",
    "\n",
    "# Finally, get the simulator backend.\n",
    "simulator_backend = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With backend created, what I need to do next is calculating POVM that describes its measurements best. To do that, following our QDT tutorial, I use DetectorTomographyFitter object from our module. In order to do that, I need to create calibration circuits and obtain their results first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.951 0.049]\n",
      "[0.047 0.953]\n",
      "[0.498 0.502]\n",
      "[0.499 0.501]\n",
      "[0.499 0.501]\n",
      "[0.496 0.504]\n"
     ]
    }
   ],
   "source": [
    "# What I want to do now, is prepare POVM for simulated backend. According to our other notebook, I prepare\n",
    "# circuits first.\n",
    "\n",
    "qdt_qubit_index = [0]\n",
    "qdt_probe_kets = povmtools.pauli_probe_eigenkets\n",
    "qdt_calibration_circuits = detector_tomography_circuits(qdt_qubit_index, qdt_probe_kets)\n",
    "\n",
    "# I then execute them on backend prepared earlier.\n",
    "shots_number = 8192\n",
    "\n",
    "# Perform a noisy simulation\n",
    "result = execute(qdt_calibration_circuits, simulator_backend, coupling_map=coupling_map, basis_gates=basis_gates,\n",
    "                 noise_model=noise_model, shots=shots_number)\\\n",
    "                 .result()\n",
    "\n",
    "# Print counts.\n",
    "for i in range(len(result.results)):\n",
    "    counts_now = result.get_counts(i)\n",
    "    frequencies_now = povmtools.counts_dict_to_frequencies_vector(counts_now)\n",
    "    print(np.round(frequencies_now,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that it is highly preferable to use as high number of shots as possible to minimize statistical errors.  \n",
    "\n",
    "Maximum likelihood POVM calculation is as easy as calling single method now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0                   1\n",
      "0  0.951083-0.000000j -0.000305-0.001404j\n",
      "1 -0.000305+0.001404j  0.046678-0.000000j\n",
      "                    0                   1\n",
      "0  0.048917+0.000000j  0.000305+0.001404j\n",
      "1  0.000305-0.001404j  0.953322+0.000000j\n"
     ]
    }
   ],
   "source": [
    "# With circuits results I can now use our Detector Tomography Fitter to obtain maximum likelihood POVM estimator.\n",
    "dtf = DetectorTomographyFitter()\n",
    "ml_povm_estimator = dtf.get_maximum_likelihood_povm_estimator([result], qdt_probe_kets)\n",
    "\n",
    "for m_i in ml_povm_estimator:\n",
    "    nice_looking_m_i = pd.DataFrame(m_i)\n",
    "    print(nice_looking_m_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With POVM calculated, we can now create and prepare mitigator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can use obtained POVM to correct to prepare mitigation object.\n",
    "mitigator = QDTErrorMitigator()\n",
    "mitigator.prepare_mitigator(ml_povm_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After those preparations, we can now check how efficient our error mitigation approach is. Let's consider two simple scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X gate circuit\n",
    "\n",
    "In this case, we will first create a one qubit circuit (initially in |0><0| state) and we will apply X (not) operation to it. In ideal scenario we would expect all counts in state |1><1|. We begin with circuit creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to check how efficient our mitigator is, we need to obtain some noisy data first.\n",
    "# We will start with preparing simple experiment.\n",
    "\n",
    "qr = QuantumRegister(1, 'qreg')\n",
    "cr = ClassicalRegister(1, 'creg')\n",
    "qc = QuantumCircuit(qr, cr)\n",
    "\n",
    "qc.x(qr[0])\n",
    "qc.measure(qr, cr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we execute this circuit on our simulator and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.042 0.958]\n"
     ]
    }
   ],
   "source": [
    "result = execute(qc, simulator_backend, coupling_map=coupling_map, basis_gates=basis_gates,\n",
    "                 noise_model=noise_model, shots=shots_number)\\\n",
    "                 .result()\n",
    "\n",
    "for i in range(len(result.results)):\n",
    "    counts_now = result.get_counts(i)\n",
    "    frequencies_now = povmtools.counts_dict_to_frequencies_vector(counts_now)\n",
    "    print(np.round(frequencies_now,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, noisy simulator returned some errors (|0><0| counts), as expected. Let's try to correct these results using our mitigator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good format\n",
      "[[0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's correct them.\n",
    "corrected_results = mitigator.apply_correction_to_qiskit_job(result)\n",
    "print(np.round(corrected_results[0],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H gate circuit\n",
    "\n",
    "In this case, we will use H (Hadamard) gate, instead of X. Everything else will be exactly like in the first scenario. We begin with creating and executing a circuit and then printing raw results of the job. We expect to obtain equal number of |1> and |0> states conuts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.491 0.509]\n"
     ]
    }
   ],
   "source": [
    "# Let's try another example.\n",
    "qr2 = QuantumRegister(1, 'qreg2')\n",
    "cr2 = ClassicalRegister(1, 'creg2')\n",
    "qc2 = QuantumCircuit(qr2, cr2)\n",
    "\n",
    "qc2.h(qr2[0])\n",
    "qc2.measure(qr2, cr2)\n",
    "\n",
    "result = execute(qc2, simulator_backend, coupling_map=coupling_map, basis_gates=basis_gates,\n",
    "                 noise_model=noise_model, shots=shots_number)\\\n",
    "                 .result()\n",
    "\n",
    "for i in range(len(result.results)):\n",
    "    counts_now = result.get_counts(i)\n",
    "    frequencies_now = povmtools.counts_dict_to_frequencies_vector(counts_now)\n",
    "    print(np.round(frequencies_now,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that again have distribution which is not perfect. Let's try to apply error mitigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good format\n",
      "[[0.492]\n",
      " [0.508]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's correct them.\n",
    "corrected_results = mitigator.apply_correction_to_qiskit_job(result)\n",
    "print(np.round(corrected_results[0],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the results are better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors in mitigation\n",
    "In the above benchmark circuits it was straightforward to assess the effectivness of mitigation - since we knew the theoretical distributions, we could simply compare the corrected statistics to this distribution.\n",
    "\n",
    "In realistic scenarios, however, if one does not know what is the underlying ideal distribution, it is impossible to assess the success of mitigation. However, following procedure described in [0], we can heuristically assses if it is likely that mitigation succeded (see theoretical background of this tutorial). \n",
    "\n",
    "We start with calculating statistical error bound. We start with setting mistake probability (in theoretical background denoted as $\\text{Pr}_{\\text{wrong}}$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check out if mitigation was success. In order to do that, we have to calculate error bounds.\n",
    "# Let's assume (according to the notation form the main paper) that alpha=0.\n",
    "\n",
    "statistical_error_mistake_probability = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need counts formatted as list or array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need counts as array. The outcomes are 0 or 1, so we can create them in straightforward way.\n",
    "counts_dict = result.get_counts()\n",
    "counts_list = [counts_dict['0'], counts_dict['1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use povmtools method to calculate statistical error bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistical errors: 0.017982870414073163\n"
     ]
    }
   ],
   "source": [
    "# We calculate statistical error bound. Let's call it epsilon.\n",
    "epsilon = povmtools.get_statistical_error_bound(counts_list, statistical_error_mistake_probability)\n",
    "print('statistical errors:',epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's, however, not enough. We'll also require correction error. Luckily, we have all the arguments necessary for its calculation using prepared povmtools method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unphysicality error: 0\n",
      "total mitigation error: 0.021520187615865282\n"
     ]
    }
   ],
   "source": [
    "#get correction matrix\n",
    "correction_matrix = mitigator.correction_matrix\n",
    "\n",
    "\n",
    "#do not forget about possible term from unphysicality. \n",
    "alpha = mitigator.distances_from_closest_probability_vector[0]\n",
    "print('unphysicality error:',alpha)\n",
    "\n",
    "\n",
    "\n",
    "# We now need the correction error bound. Let's call it delta.\n",
    "delta = povmtools.get_correction_error_bound_from_data_and_statistical_error(ml_povm_estimator,\n",
    "                                                                             correction_matrix, \n",
    "                                                                             epsilon,\n",
    "                                                                             alpha)\n",
    "\n",
    "\n",
    "print('total mitigation error:',delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that since we took a classical noise model from IBM's backend properties, the above error arises solely due to statistical fluctuations and is underestimated since it does not account for coherent errors.\n",
    "\n",
    "Last thing required for determining mitigation success is operational distance between perfect measurement and our ml_povm_estimator. We calculate it, once again, using povmtools module function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors without mitigation: 0.04893864029745742\n"
     ]
    }
   ],
   "source": [
    "# We also need operational distance, between perfect detector and our POVM. We calculate it.\n",
    "perfect_measurement = povmtools.computational_projectors(d=2) # For one qubit!\n",
    "operational_distance = povmtools.operational_distance_POVMs(ml_povm_estimator, perfect_measurement)\n",
    "print('errors without mitigation:',operational_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can check if our mitigation was likely to be a success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mitigation successfull: True\n"
     ]
    }
   ],
   "source": [
    "# Now we can check if mitigation can be considered successfull\n",
    "print(f'Mitigation successfull: {delta < operational_distance + epsilon}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Qubit error mitigation scenario\n",
    "\n",
    "Our method can easily be expanded for multiple qubits. It's done analogically to the single qubit experiments. We start with preparing noisy backend, again. We can use the same code as in one qubit scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ibmqfactory.load_account:WARNING:2020-04-14 20:29:59,119: Credentials are already in use. The existing account in the session will be replaced.\n"
     ]
    }
   ],
   "source": [
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister\n",
    "from qiskit import execute\n",
    "from qiskit import IBMQ, Aer\n",
    "from qiskit.providers.aer.noise import NoiseModel\n",
    "\n",
    "import povmtools\n",
    "from DetectorTomographyFitter import DetectorTomographyFitter\n",
    "from quantum_tomography_qiskit import detector_tomography_circuits\n",
    "from QDTErrorMitigator import QDTErrorMitigator\n",
    "\n",
    "#  What I want to have first is working noisy backend simulation. In order to do that, I will use qiskit noise model\n",
    "# and download properties of selected backend.\n",
    "\n",
    "# Build noise model from backend properties.\n",
    "provider = IBMQ.load_account()\n",
    "backend = provider.get_backend('ibmq_burlington')\n",
    "noise_model = NoiseModel.from_backend(backend)\n",
    "\n",
    "# Get coupling map from backend, why not.\n",
    "coupling_map = backend.configuration().coupling_map\n",
    "\n",
    "# Get basis gates from noise model.\n",
    "basis_gates = noise_model.basis_gates\n",
    "\n",
    "# Finally, get the simulator backend.\n",
    "simulator_backend = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the POVM. This time we need higher dimensional one, as we are concerning multi qubit scenario. The code, however, doesn't change much. The only thing we need to do is modify qdt_qubit_indices list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.915 0.043 0.04  0.002]\n",
      "[0.083 0.004 0.868 0.044]\n",
      "[0.505 0.024 0.449 0.023]\n",
      "[0.495 0.026 0.455 0.025]\n",
      "[0.502 0.026 0.448 0.024]\n",
      "[0.494 0.023 0.459 0.024]\n",
      "[0.036 0.925 0.001 0.038]\n",
      "[0.003 0.088 0.035 0.874]\n",
      "[0.024 0.506 0.02  0.45 ]\n",
      "[0.022 0.5   0.019 0.459]\n",
      "[0.021 0.508 0.022 0.448]\n",
      "[0.022 0.508 0.02  0.45 ]\n",
      "[0.465 0.492 0.021 0.023]\n",
      "[0.047 0.051 0.443 0.459]\n",
      "[0.255 0.268 0.235 0.242]\n",
      "[0.256 0.276 0.224 0.244]\n",
      "[0.264 0.265 0.231 0.24 ]\n",
      "[0.266 0.267 0.232 0.235]\n",
      "[0.476 0.48  0.022 0.022]\n",
      "[0.047 0.047 0.448 0.458]\n",
      "[0.26  0.263 0.232 0.245]\n",
      "[0.257 0.264 0.238 0.241]\n",
      "[0.269 0.266 0.236 0.229]\n",
      "[0.263 0.263 0.232 0.241]\n",
      "[0.476 0.475 0.025 0.024]\n",
      "[0.045 0.043 0.455 0.458]\n",
      "[0.268 0.27  0.227 0.235]\n",
      "[0.267 0.258 0.239 0.235]\n",
      "[0.253 0.265 0.24  0.242]\n",
      "[0.263 0.268 0.23  0.239]\n",
      "[0.478 0.481 0.021 0.02 ]\n",
      "[0.046 0.044 0.444 0.466]\n",
      "[0.252 0.277 0.234 0.236]\n",
      "[0.258 0.265 0.242 0.234]\n",
      "[0.254 0.265 0.238 0.244]\n",
      "[0.256 0.268 0.236 0.24 ]\n"
     ]
    }
   ],
   "source": [
    "# What I want to do now, is prepare POVM for simulated backend. According to our other notebook, I prepare\n",
    "# circuits first.\n",
    "\n",
    "qdt_qubit_indices = [0, 1]\n",
    "qdt_probe_kets = povmtools.pauli_probe_eigenkets\n",
    "qdt_calibration_circuits = detector_tomography_circuits(qdt_qubit_indices, qdt_probe_kets)\n",
    "\n",
    "# I then execute them on backend prepared earlier.\n",
    "shots_number = 8192\n",
    "\n",
    "# Perform a noisy simulation\n",
    "result = execute(qdt_calibration_circuits, simulator_backend, coupling_map=coupling_map, basis_gates=basis_gates,\n",
    "                 noise_model=noise_model, shots=shots_number) \\\n",
    "    .result()\n",
    "\n",
    "# Print counts.\n",
    "for i in range(len(result.results)):\n",
    "    counts_now = result.get_counts(i)\n",
    "    frequencies_now = povmtools.counts_dict_to_frequencies_vector(counts_now)\n",
    "    print(np.round(frequencies_now,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can calculate the POVM estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0                   1                   2  \\\n",
      "0  0.911396-0.000000j  0.002777+0.000452j -0.003500-0.002462j   \n",
      "1  0.002777-0.000452j  0.087679-0.000000j -0.003046-0.003397j   \n",
      "2 -0.003500+0.002462j -0.003046+0.003397j  0.038715+0.000000j   \n",
      "3  0.000684-0.000340j  0.000214+0.000448j  0.000510-0.000517j   \n",
      "\n",
      "                    3  \n",
      "0  0.000684+0.000340j  \n",
      "1  0.000214-0.000448j  \n",
      "2  0.000510+0.000517j  \n",
      "3  0.003346+0.000000j   \n",
      "\n",
      "                    0                   1                   2  \\\n",
      "0  0.041592+0.000000j -0.001744+0.000845j -0.000711-0.001183j   \n",
      "1 -0.001744-0.000845j  0.862278-0.000000j  0.006242-0.000028j   \n",
      "2 -0.000711+0.001183j  0.006242+0.000028j  0.001315-0.000000j   \n",
      "3  0.002393-0.001926j -0.002893+0.000536j -0.000124+0.001468j   \n",
      "\n",
      "                    3  \n",
      "0  0.002393+0.001926j  \n",
      "1 -0.002893-0.000536j  \n",
      "2 -0.000124-0.001468j  \n",
      "3  0.037545+0.000000j   \n",
      "\n",
      "                    0                   1                   2  \\\n",
      "0  0.045067-0.000000j -0.000848-0.001079j  0.004109+0.005288j   \n",
      "1 -0.000848+0.001079j  0.004271-0.000000j -0.001245-0.001228j   \n",
      "2  0.004109-0.005288j -0.001245+0.001228j  0.919875-0.000000j   \n",
      "3 -0.001533-0.001259j  0.001530+0.000302j  0.002068-0.000981j   \n",
      "\n",
      "                    3  \n",
      "0 -0.001533+0.001259j  \n",
      "1  0.001530-0.000302j  \n",
      "2  0.002068+0.000981j  \n",
      "3  0.089167+0.000000j   \n",
      "\n",
      "                    0                   1                   2  \\\n",
      "0  0.001945-0.000000j -0.000185-0.000218j  0.000103-0.001643j   \n",
      "1 -0.000185+0.000218j  0.045772-0.000000j -0.001952+0.004653j   \n",
      "2  0.000103+0.001643j -0.001952-0.004653j  0.040095-0.000000j   \n",
      "3 -0.001543+0.003526j  0.001149-0.001285j -0.002454+0.000030j   \n",
      "\n",
      "                    3  \n",
      "0 -0.001543-0.003526j  \n",
      "1  0.001149+0.001285j  \n",
      "2 -0.002454-0.000030j  \n",
      "3  0.869942-0.000000j   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With circuits results I can now use our Detector Tomography Fitter to obtain maximum likelihood POVM estimator.\n",
    "dtf = DetectorTomographyFitter()\n",
    "ml_povm_estimator = dtf.get_maximum_likelihood_povm_estimator([result], qdt_probe_kets)\n",
    "\n",
    "for m_i in ml_povm_estimator:\n",
    "    nice_looking_m_i = pd.DataFrame(m_i)\n",
    "    print(nice_looking_m_i,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with POVM estimator, we can prepare mitigator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can use obtained POVM to correct to prepare mitigation object.\n",
    "mitigator = QDTErrorMitigator()\n",
    "mitigator.prepare_mitigator(ml_povm_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's check how the mitigation work on several circuits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadamards circuit\n",
    "\n",
    "We begin with circuit applying Hadamard gates on both qubits. Let's prepare such circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to check how efficient our mitigator is, we need to obtain some noisy data first.\n",
    "# We will start with preparing simple experiment.\n",
    "\n",
    "qr = QuantumRegister(2, 'qreg')\n",
    "cr = ClassicalRegister(2, 'creg')\n",
    "qc = QuantumCircuit(qr, cr)\n",
    "\n",
    "qc.h(qr[0])\n",
    "qc.h(qr[1])\n",
    "qc.measure(qr, cr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then execute this circuit and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.267822265625, 0.2626953125, 0.2337646484375, 0.2357177734375]\n"
     ]
    }
   ],
   "source": [
    "result = execute(qc, simulator_backend, coupling_map=coupling_map, basis_gates=basis_gates,\n",
    "                 noise_model=noise_model, shots=shots_number) \\\n",
    "    .result()\n",
    "\n",
    "for i in range(len(result.results)):\n",
    "    counts_now = result.get_counts(i)\n",
    "    frequencies_now = povmtools.counts_dict_to_frequencies_vector(counts_now)\n",
    "    print(frequencies_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can correct them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good format\n",
      "[[0.25861098]\n",
      " [0.24791903]\n",
      " [0.24754082]\n",
      " [0.24592917]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's correct them.\n",
    "corrected_results = mitigator.apply_correction_to_qiskit_job(result)\n",
    "print(corrected_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can clarly see, that the results are better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's it try with some multi-qubit gates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNOT Circuit\n",
    "\n",
    "This time we will use a CNOT gate. First we will prepare a qubit in state |1> and then use it as a control to negate the other qubit. We expect all counts to be in state |11>. The circuit can be codded as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qiskit.circuit.instructionset.InstructionSet at 0x7f716415a9d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try another example.\n",
    "qr2 = QuantumRegister(2, 'qreg2')\n",
    "cr2 = ClassicalRegister(2, 'creg2')\n",
    "qc2 = QuantumCircuit(qr2, cr2)\n",
    "\n",
    "qc2.x(qr2[0])\n",
    "qc2.cx(qr2[0], qr2[1])\n",
    "qc2.measure(qr2, cr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing this circuits yields following results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0045166015625, 0.09423828125, 0.0411376953125, 0.860107421875]\n"
     ]
    }
   ],
   "source": [
    "result = execute(qc2, simulator_backend, coupling_map=coupling_map, basis_gates=basis_gates,\n",
    "                 noise_model=noise_model, shots=shots_number) \\\n",
    "    .result()\n",
    "\n",
    "for i in range(len(result.results)):\n",
    "    counts_now = result.get_counts(i)\n",
    "    frequencies_now = povmtools.counts_dict_to_frequencies_vector(counts_now)\n",
    "    print(frequencies_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we can see some erroneous results. Let's try to mitigate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good format\n",
      "[[0.001]\n",
      " [0.007]\n",
      " [0.005]\n",
      " [0.988]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's correct them.\n",
    "corrected_results = mitigator.apply_correction_to_qiskit_job(result)\n",
    "print(np.round(corrected_results[0],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easily enough, the results are clearly better. Let's now combine Hadamard and CNOT gate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadamard + CNOT circuit\n",
    "\n",
    "In this scenario, we will first prepare first qubit in superposition of states |0> and |1>. We will then, again, use it as a control qubit to negate the second one. We will expect equal number of counts in |00> and |11> states. The circuit can be prepared like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qiskit.circuit.instructionset.InstructionSet at 0x7f7164007bd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final example!\n",
    "qr3 = QuantumRegister(2, 'qreg2')\n",
    "cr3 = ClassicalRegister(2, 'creg2')\n",
    "qc3 = QuantumCircuit(qr3, cr3)\n",
    "\n",
    "qc3.h(qr3[0])\n",
    "qc3.cx(qr3[0], qr2[1])\n",
    "qc3.measure(qr3, cr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now execute it and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45263671875, 0.06982421875, 0.041259765625, 0.436279296875]\n"
     ]
    }
   ],
   "source": [
    "result = execute(qc3, simulator_backend, coupling_map=coupling_map, basis_gates=basis_gates,\n",
    "                 noise_model=noise_model, shots=shots_number) \\\n",
    "    .result()\n",
    "\n",
    "for i in range(len(result.results)):\n",
    "    counts_now = result.get_counts(i)\n",
    "    frequencies_now = povmtools.counts_dict_to_frequencies_vector(counts_now)\n",
    "    print(frequencies_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's some room for improvement. Let's apply the mitigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good format\n",
      "[[0.494]\n",
      " [0.003]\n",
      " [0.002]\n",
      " [0.5  ]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's correct them.\n",
    "corrected_results = mitigator.apply_correction_to_qiskit_job(result)\n",
    "print(np.round(corrected_results[0],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the results are clearly better.\n",
    "\n",
    "We can, as in single-qubit example, check if our criterion for assesing mitigation success works in this case as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistical errors: 0.021027423958378727\n",
      "unphysicality error: 0\n",
      "total mitigation error: 0.04079362488580693\n"
     ]
    }
   ],
   "source": [
    "# We need counts as array. The outcomes are 0 or 1, so we can create them in straightforward way.\n",
    "counts_dict = result.get_counts()\n",
    "counts_list = np.array(povmtools.counts_dict_to_frequencies_vector(counts_dict))*shots_number\n",
    "\n",
    "\n",
    "# We calculate statistical error bound. Let's call it epsilon.\n",
    "epsilon = povmtools.get_statistical_error_bound(counts_list, statistical_error_mistake_probability)\n",
    "print('statistical errors:',epsilon)\n",
    "\n",
    "\n",
    "\n",
    "#get correction matrix\n",
    "correction_matrix = mitigator.correction_matrix\n",
    "\n",
    "\n",
    "#do not forget about possible term from unphysicality. \n",
    "alpha = mitigator.distances_from_closest_probability_vector[0]\n",
    "print('unphysicality error:',alpha)\n",
    "\n",
    "\n",
    "\n",
    "# We now need the correction error bound. Let's call it delta.\n",
    "delta = povmtools.get_correction_error_bound_from_data_and_statistical_error(ml_povm_estimator,\n",
    "                                                                             correction_matrix, \n",
    "                                                                             epsilon,\n",
    "                                                                             alpha)\n",
    "\n",
    "\n",
    "print('total mitigation error:',delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that since we took a classical noise model from IBM's backend properties, the above error arises solely due to statistical fluctuations and is underestimated since it does not account for coherent errors. Here errors are assumed to be uncorellated, which underestimates their magnitude.\n",
    "\n",
    "\n",
    "Note that mitigation error is higher than in case of single-qubit experiments. This is due to the fact that sampling complexity is higher for 4-dimensional probability distributions. However, we expect that also errors without mitigation increase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors without mitigation: 0.13807070090100917\n",
      "Mitigation successfull: True\n"
     ]
    }
   ],
   "source": [
    "# We need operational distance between perfect detector and our POVM. We calculate it.\n",
    "perfect_measurement = povmtools.computational_projectors(d=4) # For two qubits\n",
    "operational_distance = povmtools.operational_distance_POVMs(ml_povm_estimator, perfect_measurement)\n",
    "print('errors without mitigation:',operational_distance)\n",
    "\n",
    "# Now we can check if mitigation can be considered succesfull\n",
    "print(f'Mitigation successfull: {delta < operational_distance + epsilon}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final remark one should be aware that the results of the mitigation and its success in particular, might depend on quantum detector tomography method used during POVM calculation. In our work we used reconstruction algorithm from [1] with overcomplete Pauli basis as probe states. For more information see [0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[0] Filip B. Maciejewski, Zoltán Zimborás, Michał Oszmaniec, *Mitigation of readout noise in near-term quantum devices by classical post-processing based on detector tomography*, arxiv preprint, https://arxiv.org/abs/1907.08518 (2019)\n",
    "\n",
    "[1] Z. Hradil, J. Řeháček, J. Fiurášek, and M. Ježek, “3 maximum-likelihood methods in quantum mechanics,” in Quantum\n",
    "State Estimation, edited by M. Paris and J. Řeháček (Springer Berlin Heidelberg, Berlin, Heidelberg, 2004) pp. 59–112.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
